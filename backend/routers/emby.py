from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks, Request
from sqlalchemy.orm import Session
from database import get_db
from models import MediaTag
from pydantic import BaseModel
from typing import List, Optional, Dict
import requests
import json
import logging
import traceback
import asyncio  # ğŸ‘ˆ å¿…é¡»å¼•å…¥ï¼šç”¨äºå¼‚æ­¥å»¶æ—¶(é˜²æŠ–)
import re       # ğŸ‘ˆ å¿…é¡»å¼•å…¥ï¼šç”¨äºæ­£åˆ™æ¸…æ´—å­—ç¬¦ä¸²
from openai import OpenAI
from config.settings import load_config
import time

# å¼•å…¥æœåŠ¡å±‚å‡½æ•° (ç¡®ä¿ services/emby_service.py ä¹Ÿæ˜¯æœ€æ–°ç‰ˆ)
from services.emby_service import get_item_info, update_item_tags

router = APIRouter()
logger = logging.getLogger("uvicorn")

# ==========================================
# ğŸ“‹ Pydantic æ¨¡å‹å®šä¹‰ (è¯·æ±‚ä½“ç»“æ„)
# ==========================================
class AppConfig(BaseModel):
    emby_host: str = ""
    emby_api_key: str = ""
    emby_user_id: str = ""
    sf_api_key: str = ""

class LibraryItemsRequest(AppConfig):
    library_id: str
    limit: int = 100
    start_index: int = 0

class SearchRequest(AppConfig):
    search_term: str

class AISingleRequest(AppConfig):
    item_id: str
    force_refresh: bool = False

class TagUpdateRequest(AppConfig):
    item_id: str
    tags: List[str]        # æœ€ç»ˆè¦ä¿å­˜çš„æ ‡ç­¾åˆ—è¡¨
    overwrite: bool = True # True=è¦†ç›–æ¨¡å¼(æ”¯æŒåˆ é™¤), False=åˆå¹¶æ¨¡å¼(åªå¢ä¸å‡)

class AIBatchRequest(AppConfig):
    item_ids: List[str]
    force_refresh: bool = False

# ==========================================
# ğŸ› ï¸ å…¨å±€å·¥å…· & è¾…åŠ©å‡½æ•°
# ==========================================

# å…¨å±€ä»»åŠ¡å­—å…¸ï¼šç”¨äºå­˜å‚¨æ­£åœ¨å€’è®¡æ—¶çš„å‰§é›†ä»»åŠ¡
# Key: SeriesId (å‰§é›†ID), Value: asyncio.Task (å¼‚æ­¥ä»»åŠ¡å¯¹è±¡)
SERIES_TASKS: Dict[str, asyncio.Task] = {}

def clean_string(s):
    """
    æ¸…æ´—å­—ç¬¦ä¸²ï¼Œå»é™¤å¹²æ‰°å­—ç¬¦
    Emby æœ‰æ—¶ä¼šåœ¨æ ‡é¢˜é‡ŒåŒ…å« \u200e (LRM) ç­‰ä¸å¯è§å­—ç¬¦ï¼Œå¯¼è‡´ key åŒ¹é…å¤±è´¥
    """
    if not s: return ""
    return re.sub(r'[\u200b-\u200f\ufeff]', '', s).strip()

def ask_ai(items, api_key):
    """
    è°ƒç”¨ SiliconFlow (DeepSeek) AI è¿›è¡Œåˆ†æ
    :param items: åŒ…å« name, year, overview çš„å­—å…¸åˆ—è¡¨
    :return: JSON æ ¼å¼çš„æ ‡ç­¾å­—å…¸ {"å‰§å": ["æ ‡ç­¾1", ...]}
    """
    if not items or not api_key: return {}
    
    client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")
    
    # æ„é€ ç®€åŒ–ç‰ˆçš„æ•°æ®å‘ç»™ AIï¼ŒèŠ‚çœ Token ä¸”æé«˜å‡†ç¡®ç‡
    simple_list = []
    for i in items:
        simple_list.append({
            "name": i.get("Name"),
            "year": i.get("ProductionYear"),
            "overview": i.get("Overview", "")[:150] # æˆªå–å‰150å­—ç®€ä»‹ï¼Œé˜²æ­¢ Token æº¢å‡º
        })

    logger.info(f"ğŸ¤– [AIè¯·æ±‚] æ­£åœ¨è¯·æ±‚ AI åˆ†æ {len(simple_list)} ä¸ªé¡¹ç›®...")

    prompt = f"""
    è¯·ä¸ºä»¥ä¸‹å½±è§†ä½œå“æ‰“ä¸Š 8-10 ä¸ªç²¾å‡†çš„ä¸­æ–‡æ ‡ç­¾ã€‚
    æ ‡ç­¾èŒƒå›´å‚è€ƒï¼šé¢˜æ(å¦‚ç§‘å¹»,å¤è£…), é£æ ¼(å¦‚æ‚¬ç–‘,å–œå‰§), å…ƒç´ (å¦‚ç©¿è¶Š,æƒè°‹), å—ä¼—(å¦‚èŒåœº,å¤§å¥³ä¸»)ã€‚
    è¦æ±‚ï¼š
    1. åªè¿”å›çº¯ JSON æ ¼å¼
    2. ä¸è¦åŒ…å« Markdown ä»£ç å—
    3. æ ¼å¼ç¤ºä¾‹: {{"ä½œå“å": ["æ ‡ç­¾1", "æ ‡ç­¾2"]}}
    
    æ•°æ®å†…å®¹ï¼š{json.dumps(simple_list, ensure_ascii=False)}
    """
    try:
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2, stream=False
        )
        content = response.choices[0].message.content
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ Markdown æ ‡è®° (```json ... ```)
        content = content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        logger.error(f"âŒ AI è§£æè¿”å›å¤±è´¥: {e}")
        return {}

# ==========================================
# â³ æ ¸å¿ƒé€»è¾‘ 1: å‰§é›†é˜²æŠ–å¤„ç† (Series/Episode)
# ==========================================

async def analyze_series_finally(series_id: str, series_name: str):
    """
    å‰§é›†é˜²æŠ–ç»“æŸåçš„æœ€ç»ˆæ‰§è¡Œé€»è¾‘ã€‚
    åªæœ‰å½“ 15ç§’ å†…æ²¡æœ‰æ–°çš„é›†æ•°å…¥åº“æ—¶ï¼Œæ‰ä¼šæ‰§è¡Œæ­¤å‡½æ•°ã€‚
    """
    try:
        # 1. ç­‰å¾…é˜²æŠ–æ—¶é—´ (è®© Emby æ•°æ®åº“å†™å…¥å®Œæˆï¼Œç­‰å¾…åŒä¸€å­£å…¶ä»–é›†æ•°å…¥åº“)
        await asyncio.sleep(15) 
        
        # ä»»åŠ¡æ‰§è¡Œäº†ï¼Œä»å…¨å±€å­—å…¸é‡ŒæŠŠè‡ªå·±ç§»é™¤
        if series_id in SERIES_TASKS:
            del SERIES_TASKS[series_id]

        logger.info(f"â³ [é˜²æŠ–ç»“æŸ] å¼€å§‹å¤„ç†æ•´éƒ¨å‰§é›†: {series_name} (ID: {series_id})")

        # 2. æ£€æŸ¥é…ç½®
        config = load_config()
        sf_api_key = config.get("sf_api_key")
        if not sf_api_key: return

        # 3. æŸ¥è¯¢ Emby è·å–æœ€æ–°çŠ¶æ€
        # (ç»è¿‡ 15s ç­‰å¾…ï¼ŒEmby æ¥å£è‚¯å®šé€šäº†ï¼Œä¸ç”¨æ‹…å¿ƒ 404)
        series_info = get_item_info(series_id)
        if not series_info:
            logger.error(f"âŒ æ— æ³•è·å–å‰§é›†è¯¦æƒ…: {series_id}")
            return

        # 4. å¹‚ç­‰æ€§æ£€æŸ¥ï¼šå¦‚æœå·²ç»æœ‰æ ‡ç­¾ï¼Œå°±ä¸å†æµªè´¹ AI Token
        current_tags = series_info.get("Tags", [])
        if current_tags:
            logger.info(f"   ğŸ›‘ [è·³è¿‡] å‰§é›†ã€Š{series_name}ã€‹å·²æœ‰æ ‡ç­¾: {current_tags}")
            return

        # 5. å‡†å¤‡ AI æ•°æ®
        clean_name = clean_string(series_info.get("Name", series_name))
        target_info = {
            "Name": clean_name,
            "ProductionYear": series_info.get("ProductionYear"),
            "Overview": series_info.get("Overview", "")
        }
        
        logger.info(f"   ğŸ¤– æ­£åœ¨è¯·æ±‚ AI åˆ†æå‰§é›†: [{clean_name}] ...")
        
        # 6. è°ƒç”¨ AI
        ai_result = ask_ai([target_info], sf_api_key)
        
        # 7. è§£æ AI ç»“æœä¸åŒ¹é…
        suggested_tags = []
        if clean_name in ai_result:
            suggested_tags = ai_result[clean_name] # ç²¾ç¡®åŒ¹é…
        else:
            # æ¨¡ç³ŠåŒ¹é… (é˜²æ­¢ AI è¿”å›çš„åå­—ç•¥æœ‰ä¸åŒ)
            for k, v in ai_result.items():
                if clean_string(k) == clean_name or clean_name in k:
                    suggested_tags = v
                    break
            # å…œåº• (å¦‚æœ AI åªè¿”å›äº†ä¸€ä¸ªç»“æœï¼Œå°±é»˜è®¤æ˜¯å®ƒ)
            if not suggested_tags and len(ai_result) == 1:
                suggested_tags = list(ai_result.values())[0]

        # 8. æ‰§è¡Œæ›´æ–°
        if suggested_tags:
            logger.info(f"   ğŸ· [AIå®Œæˆ] ä¸ºã€Š{clean_name}ã€‹æ‰“æ ‡: {suggested_tags}")
            update_item_tags(series_id, suggested_tags)
        else:
            logger.warning(f"   âš ï¸ AI æœªè¿”å›æœ‰æ•ˆæ ‡ç­¾: {clean_name}")

    except asyncio.CancelledError:
        # å¦‚æœåœ¨ sleep æœŸé—´è¢« cancel() äº†ï¼Œè¯´æ˜åˆæœ‰æ–°é›†æ•°æ¥äº†
        logger.info(f"   ğŸ”„ [é‡ç½®è®¡æ—¶] {series_name} åˆæœ‰æ–°é›†æ•°å…¥åº“ï¼Œæ¨è¿Ÿåˆ†æ...")
        raise
    except Exception as e:
        logger.error(f"âŒ å‰§é›†åˆ†æä»»åŠ¡å¼‚å¸¸: {e}")

# ==========================================
# ğŸš€ æ ¸å¿ƒé€»è¾‘ 2: å…¥åº“äº‹ä»¶åˆ†æµ (Movie vs Series)
# ==========================================

async def process_emby_item_added(payload: dict):
    """
    åå°ä»»åŠ¡ï¼šå¤„ç† Emby Webhook å…¥åº“äº‹ä»¶
    æ ¹æ®ç±»å‹åˆ†æµï¼šç”µå½±ç›´é€šè½¦ vs å‰§é›†é˜²æŠ–æ± 
    """
    try:
        # 1. åŸºç¡€ä¿¡æ¯æå–
        item = payload.get("Item", {})
        if not item: return

        item_id = item.get("Id")
        name = item.get("Name", "")
        item_type = item.get("Type")
        
        # -------------------------------------------------------
        # åˆ†æ”¯ A: ç”µå½± (Movie) -> ç«‹å³æ‰§è¡Œï¼Œæ— å»¶è¿Ÿ
        # -------------------------------------------------------
        if item_type == "Movie":
            logger.info(f"ğŸ¬ [ç”µå½±å…¥åº“] {name}ï¼Œç«‹å³å¼€å§‹ AI åˆ†æ...")
            
            # æ£€æŸ¥é…ç½®
            config = load_config()
            sf_api_key = config.get("sf_api_key")
            if not sf_api_key: return

            # ç›´æ¥åˆ©ç”¨ Webhook æ•°æ®æ„é€ è¯·æ±‚ (ä¸å›æŸ¥ Embyï¼Œé˜²æ­¢ 404)
            clean_name = clean_string(name)
            target_info = {
                "Name": clean_name,
                "ProductionYear": item.get("ProductionYear"),
                "Overview": item.get("Overview", ""),
                "ProviderIds": item.get("ProviderIds", {})
            }
            
            # è°ƒç”¨ AI
            ai_result = ask_ai([target_info], sf_api_key)
            
            # è§£æåŒ¹é…é€»è¾‘
            suggested_tags = []
            if clean_name in ai_result:
                suggested_tags = ai_result[clean_name]
            else:
                # æ¨¡ç³ŠåŒ¹é…
                for k, v in ai_result.items():
                    if clean_string(k) == clean_name or clean_name in k:
                        suggested_tags = v
                        break
                # å…œåº•
                if not suggested_tags and len(ai_result) == 1:
                    suggested_tags = list(ai_result.values())[0]

            # æ›´æ–° Emby
            if suggested_tags:
                logger.info(f"   ğŸ· å‡†å¤‡æ‰“æ ‡ç­¾: {suggested_tags}")
                await asyncio.sleep(1) # å°ç¡1ç§’ï¼Œé˜²æ­¢ Emby æ•°æ®åº“è¢«é”
                update_item_tags(item_id, suggested_tags)
            return

        # -------------------------------------------------------
        # åˆ†æ”¯ B: å‰§é›†/å•é›† (Series/Episode) -> è¿›å…¥é˜²æŠ–æ± 
        # -------------------------------------------------------
        target_series_id = None
        target_series_name = ""

        # æå–å‰§é›† ID (æ— è®ºæ˜¯å•é›†è¿˜æ˜¯æ•´å­£ï¼Œéƒ½å½’å¹¶åˆ° SeriesID)
        if item_type == "Series":
            target_series_id = item_id
            target_series_name = name
        elif item_type == "Episode":
            target_series_id = item.get("SeriesId") or item.get("ParentId")
            target_series_name = item.get("SeriesName", "")

        # å¦‚æœèƒ½æå–åˆ° SeriesIdï¼Œè¿›å…¥é˜²æŠ–é˜Ÿåˆ—
        if target_series_id:
            # å¦‚æœå·²æœ‰ä»»åŠ¡åœ¨è·‘ï¼Œå–æ¶ˆå®ƒï¼ˆç›¸å½“äºé‡ç½®è®¡æ—¶å™¨ï¼‰
            if target_series_id in SERIES_TASKS:
                SERIES_TASKS[target_series_id].cancel()
            
            # åˆ›å»ºæ–°ä»»åŠ¡ï¼š15ç§’åæ‰§è¡Œ
            logger.info(f"   â± [é˜²æŠ–è®¡æ—¶] {target_series_name} (ID: {target_series_id}) - 15ç§’åæ‰§è¡Œ")
            task = asyncio.create_task(analyze_series_finally(target_series_id, target_series_name))
            SERIES_TASKS[target_series_id] = task
        
    except Exception as e:
        logger.error(f"âŒ åå°ä»»åŠ¡å¼‚å¸¸: {e}")
        logger.error(traceback.format_exc())

# ==========================================
# ğŸ“¡ æ¥å£: Webhook æ¥æ”¶
# ==========================================

@router.post("/webhook/emby")
async def emby_webhook(request: Request, background_tasks: BackgroundTasks):
    content_type = request.headers.get("content-type", "")
    try:
        payload = {}
        # å…¼å®¹æ€§è§£æï¼šæ”¯æŒ JSON å’Œ Form è¡¨å•
        if "application/json" in content_type:
            payload = await request.json()
        elif "multipart/form-data" in content_type or "application/x-www-form-urlencoded" in content_type:
            form = await request.form()
            data_str = form.get("data")
            if data_str:
                payload = json.loads(data_str)
            else:
                try: payload = json.loads(await request.body())
                except: pass
        else:
            try: payload = await request.json()
            except: return {"status": "unsupported"}

        event = payload.get("Event")
        
        # ç›‘å¬ item.created (å•é›†å…¥åº“) å’Œ library.new (æ•´å­£å…¥åº“)
        if event in ["item.created", "library.new"]:
            background_tasks.add_task(process_emby_item_added, payload)
        
        return {"status": "received"}
        
    except Exception as e:
        logger.error(f"âŒ Webhook æ¥æ”¶é”™è¯¯: {e}")
        return {"status": "error"}

# ==========================================
# ğŸ’¾ æ¥å£: æ‰‹åŠ¨ä¿å­˜æ ‡ç­¾ (å¥å£®ç‰ˆ)
# ==========================================

@router.post("/save_tags")
def save_tags(req: TagUpdateRequest, db: Session = Depends(get_db)):
    """
    å‰ç«¯æ‰‹åŠ¨ç‚¹å‡»'ä¿å­˜'æ—¶è°ƒç”¨æ­¤æ¥å£
    åŒ…å«é€»è¾‘ï¼šè§£é”å…ƒæ•°æ®ã€æ¸…ç†åªè¯»å­—æ®µã€è¦†ç›–/åˆå¹¶æ ‡ç­¾ã€åŒæ­¥æ•°æ®åº“
    """
    logger.info(f"ğŸ’¾ [ä¿å­˜æ ‡ç­¾] ID: {req.item_id}, æ¨¡å¼: {'è¦†ç›–' if req.overwrite else 'åˆå¹¶'}")
    
    # 1. éªŒè¯é…ç½®
    if not req.emby_host or not req.emby_api_key:
        raise HTTPException(status_code=400, detail="æœªé…ç½® Emby Host æˆ– API Key")

    headers = {"X-Emby-Token": req.emby_api_key, "Content-Type": "application/json"}
    
    # 2. è·å–è¯¦æƒ… (æ˜¾å¼è¯·æ±‚ LockData, Tags å­—æ®µ)
    get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
    params = {'api_key': req.emby_api_key, 'Fields': 'Tags,TagItems,LockData,LockedFields'}
    
    try:
        res = requests.get(get_url, params=params, headers=headers)
        if res.status_code != 200:
             raise HTTPException(status_code=400, detail=f"æ— æ³•è·å–ç‰©å“: {res.text}")
        item_data = res.json()
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

    # 3. è®¡ç®—æœ€ç»ˆæ ‡ç­¾
    current_tags = item_data.get('Tags', []) or []
    if req.overwrite:
        final_tags = req.tags  # è¦†ç›–æ¨¡å¼ï¼šå®Œå…¨ä¿¡ä»»å‰ç«¯ä¼ æ¥çš„åˆ—è¡¨
    else:
        final_tags = list(set(current_tags + req.tags)) # åˆå¹¶æ¨¡å¼

    # 4. å‡†å¤‡å†™å…¥æ•°æ®
    item_data['Tags'] = final_tags
    
    # ğŸ”¥ å…³é”®ï¼šå¼ºåˆ¶è§£é”å…ƒæ•°æ®ï¼Œå¦åˆ™æ— æ³•å†™å…¥
    if item_data.get('LockData'): item_data['LockData'] = False
    if item_data.get('LockedFields'): item_data['LockedFields'] = []

    # ğŸ”¥ å…³é”®ï¼šæ¸…ç†åªè¯»å­—æ®µ (å‘é€è¿™äº›å› Emby ä¼šæŠ¥é”™)
    for k in ['MediaSources', 'PlayUserData', 'SeasonUserData', 'Container', 'Size', 'TagItems']:
        if k in item_data: del item_data[k]

    # 5. æäº¤æ›´æ–°
    post_url = f"{req.emby_host}/emby/Items/{req.item_id}"
    try:
        update_res = requests.post(post_url, json=item_data, headers=headers, params={'api_key': req.emby_api_key})
        if update_res.status_code not in [200, 204]:
             raise HTTPException(status_code=400, detail=update_res.text)
        
        # 6. åŒæ­¥æœ¬åœ°æ•°æ®åº“ç¼“å­˜
        db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
        if db_item:
            db_item.tags = final_tags
            if item_data.get("Name"): db_item.name = item_data.get("Name")
        else:
            db.add(MediaTag(item_id=req.item_id, name=item_data.get("Name","Unknown"), tags=final_tags))
        db.commit()

        return {"status": "success", "tags": final_tags}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# ğŸ¤– æ¥å£: AI å•ä¸ªåˆ†æ (å‰ç«¯ç‚¹å‡» 'AIåˆ†æ' æŒ‰é’®)
# ==========================================

@router.post("/ai_single")
def ai_analyze_single(req: AISingleRequest, db: Session = Depends(get_db)):
    try:
        # 1. ä¼˜å…ˆæŸ¥åº“ (é™¤éå¼ºåˆ¶åˆ·æ–°)
        if not req.force_refresh:
            cached = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
            if cached:
                return {"id": req.item_id, "name": cached.name, "suggested_tags": cached.tags, "source": "database"}

        # 2. æŸ¥ Emby è·å–è¯¦æƒ…
        get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
        try:
            item_res = requests.get(get_url, params={'api_key': req.emby_api_key})
            item_res.raise_for_status()
            item = item_res.json()
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Emby Error: {str(e)}")

        # æ¸…æ´—åå­—
        raw_name = item.get('Name', '')
        name = clean_string(raw_name)
        item['Name'] = name # æ›¿æ¢ç»™ AIï¼Œæé«˜å‡†ç¡®åº¦

        # 3. è°ƒç”¨ AI
        ai_res = ask_ai([item], req.sf_api_key)
        
        # 4. åŒ¹é…ç»“æœ
        if name in ai_res:
            suggested = ai_res[name]
        else:
            # æ¨¡ç³ŠåŒ¹é…
            found_key = None
            for k in ai_res.keys():
                if clean_string(k) == name or name in clean_string(k):
                    found_key = k
                    break
            suggested = ai_res[found_key] if found_key else (list(ai_res.values())[0] if len(ai_res)==1 else [])

        if not suggested:
            raise HTTPException(status_code=500, detail="AI è¿”å›ç©ºç»“æœ")

        # 5. å†™å…¥æ•°æ®åº“ç¼“å­˜
        db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
        if db_item:
            db_item.tags = suggested
            db_item.name = name
        else:
            db.add(MediaTag(item_id=req.item_id, name=name, tags=suggested))
        db.commit()

        return {"id": req.item_id, "name": name, "suggested_tags": suggested, "source": "ai"}

    except Exception as e:
        logger.error(f"AI Single Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# ğŸ“š å…¶ä»–åŸºç¡€æ¥å£ (åˆ—è¡¨ã€æœç´¢ç­‰)
# ==========================================

@router.post("/libraries")
def get_libs(config: AppConfig):
    """è·å– Emby åª’ä½“åº“åˆ—è¡¨"""
    url = f"{config.emby_host}/emby/Library/VirtualFolders"
    try:
        res = requests.get(url, params={'api_key': config.emby_api_key}, timeout=5)
        res.raise_for_status()
        return res.json()
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

def process_emby_items(items):
    """å¤„ç† Emby è¿”å›çš„é¡¹ç›®åˆ—è¡¨ (æ ¼å¼åŒ–)"""
    result = []
    for item in items:
        # å…¼å®¹ Tags å’Œ TagItems
        tags = item.get('Tags', [])
        if not tags and item.get('TagItems'):
            tags = [t.get('Name') for t in item.get('TagItems')]
        result.append({
            "id": item['Id'], "name": item.get('Name'),
            "year": item.get('ProductionYear'), "current_tags": tags,
            "overview": item.get('Overview', '')
        })
    return result

@router.post("/library_items")
def get_library_items(req: LibraryItemsRequest):
    """è·å–æŒ‡å®šåº“ä¸‹çš„åª’ä½“é¡¹"""
    url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items"
    params = {
        'IncludeItemTypes': 'Series,Movie', 'Recursive': 'true',
        'ParentId': req.library_id, 'Fields': 'Tags,TagItems,OriginalTitle,ProductionYear,Overview',
        'StartIndex': req.start_index, 'SortBy': 'DateCreated', 'SortOrder': 'Descending',
        'api_key': req.emby_api_key
    }
    if req.limit != -1: params['Limit'] = req.limit
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        return {"items": process_emby_items(res.json().get('Items', [])), "total": res.json().get('TotalRecordCount')}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.post("/search_items")
def search_items(req: SearchRequest):
    """æœç´¢åª’ä½“é¡¹"""
    url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items"
    params = {
        'IncludeItemTypes': 'Series,Movie', 'Recursive': 'true',
        'SearchTerm': req.search_term, 'Fields': 'Tags,TagItems,OriginalTitle,ProductionYear,Overview',
        'api_key': req.emby_api_key
    }
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        return {"items": process_emby_items(res.json().get('Items', []))}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.post("/ai_batch")
def ai_analyze_batch(req: AIBatchRequest, db: Session = Depends(get_db)):
    """æ‰¹é‡ AI åˆ†æ"""
    logger.info(f"ğŸ“¦ æ‰¹é‡ AI: {len(req.item_ids)} ä¸ª")
    items_to_process = []
    id_map = {}
    
    # 1. ç­›é€‰éœ€è¦åˆ†æçš„é¡¹ç›® (æ— ç¼“å­˜æˆ–å¼ºåˆ¶åˆ·æ–°)
    for item_id in req.item_ids:
        if not req.force_refresh:
            cached = db.query(MediaTag).filter(MediaTag.item_id == item_id).first()
            if cached and cached.tags: continue

        try:
            url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{item_id}"
            res = requests.get(url, params={'api_key': req.emby_api_key})
            if res.status_code == 200:
                d = res.json()
                clean_name = clean_string(d.get('Name'))
                d['Name'] = clean_name
                items_to_process.append(d)
                id_map[clean_name] = item_id
        except: pass

    if not items_to_process: return {"status": "skipped"}

    # 2. æ‰¹é‡è°ƒç”¨ AI
    ai_results = ask_ai(items_to_process, req.sf_api_key)
    success_count = 0
    results_map = {}

    # 3. åŒ¹é…ç»“æœå¹¶å…¥åº“
    for item in items_to_process:
        name = item['Name']
        item_id = id_map.get(name)
        suggested = ai_results.get(name) or []
        
        if not suggested:
             # ç®€å•æ¨¡ç³ŠåŒ¹é…
             for k, v in ai_results.items():
                 if name in k or k in name:
                     suggested = v
                     break

        if suggested:
            db_item = db.query(MediaTag).filter(MediaTag.item_id == item_id).first()
            if db_item:
                db_item.tags = suggested
                db_item.name = name
            else:
                db.add(MediaTag(item_id=item_id, name=name, tags=suggested))
            results_map[item_id] = suggested
            success_count += 1
            
    db.commit()
    return {"status": "success", "results": results_map}