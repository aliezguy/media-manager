from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from database import get_db
from models import MediaTag
from pydantic import BaseModel
from typing import List, Optional
import requests
import json
import logging
import traceback
import re          # ğŸ‘ˆğŸ‘ˆğŸ‘ˆ å¿…é¡»è¡¥ä¸Šè¿™ä¸€è¡Œï¼
from openai import OpenAI
from config.settings import load_config
import time

router = APIRouter()
logger = logging.getLogger("uvicorn")
# ... åœ¨è¿™é‡Œç²˜è´´ä½ åŸ main.py é‡Œ define çš„ Pydantic æ¨¡å‹ (LibraryItemsRequest ç­‰) ...
# --- Pydantic æ¨¡å‹ ---
class AppConfig(BaseModel):
    emby_host: str = ""
    emby_api_key: str = ""
    emby_user_id: str = ""
    sf_api_key: str = ""

class LibraryItemsRequest(AppConfig):
    library_id: str
    limit: int = 100
    start_index: int = 0

class SearchRequest(AppConfig):
    search_term: str

class AISingleRequest(AppConfig):
    item_id: str
    force_refresh: bool = False

class TagUpdateRequest(AppConfig):
    item_id: str
    tags: List[str] # æœ€ç»ˆè¦ä¿å­˜çš„æ ‡ç­¾åˆ—è¡¨
    overwrite: bool = True # é»˜è®¤ä¸ºè¦†ç›–æ¨¡å¼ï¼Œæ”¯æŒåˆ é™¤

# æ‰¹é‡è¯·æ±‚æ¨¡å‹
class AIBatchRequest(AppConfig):
    item_ids: List[str] # æ¥æ”¶ä¸€ç»„ ID
    force_refresh: bool = False

# ... åœ¨è¿™é‡Œç²˜è´´ process_emby_items, ask_ai ç­‰è¾…åŠ©å‡½æ•° ...
# ----------------------------------------------
# æ–°å¢ï¼šåç§°æ¸…æ´—å·¥å…·å‡½æ•°
# ----------------------------------------------
def clean_string(s):
    if not s: return ""
    # å»é™¤ \u200e (LRM), \u200f (RLM), \ufeff (BOM) ç­‰ä¸å¯è§å­—ç¬¦
    # åŒæ—¶ä¹Ÿå»é™¤é¦–å°¾ç©ºæ ¼
    return re.sub(r'[\u200b-\u200f\ufeff]', '', s).strip()    

# --- æ ¸å¿ƒé€»è¾‘ ---

def ask_ai(items, api_key):
    if not items or not api_key: return {}
    
    client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")
    simple_list = [{"name": i.get('Name'), "year": i.get('ProductionYear')} for i in items]
    
    logger.info(f"ğŸ¤– æ­£åœ¨è¯·æ±‚ AIï¼Œå‰§é›†ä¿¡æ¯: {simple_list}")

    prompt = f"""
    è¯·ä¸ºä»¥ä¸‹ç”µè§†å‰§æ‰“ä¸Š 8-10 ä¸ªç²¾å‡†çš„ä¸­æ–‡æ ‡ç­¾ã€‚
    æ ‡ç­¾èŒƒå›´åŒ…æ‹¬ä½†ä¸é™äºï¼šé¢˜æ(å¦‚å¤è£…,ç§‘å¹»)ã€é£æ ¼(å¦‚æ‚¬ç–‘,å–œå‰§)ã€å—ä¼—(å¦‚å¤§å¥³ä¸»,èŒåœº)ã€å…ƒç´ (å¦‚æƒè°‹,ç©¿è¶Š)ã€‚
    åªè¿”å›çº¯JSONæ ¼å¼ï¼Œä¸è¦Markdownæ ¼å¼ï¼Œä¸è¦ä»£ç å—ï¼š{{"å‰§å": ["æ ‡ç­¾1", "æ ‡ç­¾2"]}}
    
    å‰§é›†ï¼š{json.dumps(simple_list, ensure_ascii=False)}
    """
    try:
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2, stream=False
        )
        content = response.choices[0].message.content
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ è°ƒè¯•å…³é”®ï¼šæ‰“å° AI è¿”å›çš„åŸå§‹å­—ç¬¦ä¸² ğŸ”¥ğŸ”¥ğŸ”¥
        logger.info(f"ğŸ“¦ [DEBUG] AI åŸå§‹è¿”å›å†…å®¹: \n{content}")

        # æ¸…ç†å¯èƒ½çš„ markdown æ ‡è®°
        content = content.replace("```json", "").replace("```", "").strip()
        
        return json.loads(content)
    except Exception as e:
        # ğŸ”¥ğŸ”¥ğŸ”¥ è°ƒè¯•å…³é”®ï¼šæ‰“å°å®Œæ•´æŠ¥é”™å †æ ˆ ğŸ”¥ğŸ”¥ğŸ”¥
        logger.error(f"âŒ AI è§£æå¤±è´¥: {e}")
        logger.error(traceback.format_exc()) # æ‰“å°è¯¦ç»†æŠ¥é”™ä½ç½®
        return {}
    if not items or not api_key: return {}
    client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")
    simple_list = [{"name": i.get('Name'), "year": i.get('ProductionYear')} for i in items]
    
    prompt = f"""
    è¯·ä¸ºä»¥ä¸‹ç”µè§†å‰§æ‰“ä¸Š 8-10 ä¸ªç²¾å‡†çš„ä¸­æ–‡æ ‡ç­¾ã€‚
    æ ‡ç­¾èŒƒå›´åŒ…æ‹¬ä½†ä¸é™äºï¼šé¢˜æ(å¦‚å¤è£…,ç§‘å¹»)ã€é£æ ¼(å¦‚æ‚¬ç–‘,å–œå‰§)ã€å—ä¼—(å¦‚å¤§å¥³ä¸»,èŒåœº)ã€å…ƒç´ (å¦‚æƒè°‹,ç©¿è¶Š)ã€‚
    åªè¿”å›çº¯JSONæ ¼å¼ï¼š{{"å‰§å": ["æ ‡ç­¾1", "æ ‡ç­¾2"]}}
    
    å‰§é›†ï¼š{json.dumps(simple_list, ensure_ascii=False)}
    """
    try:
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2, stream=False
        )
        content = response.choices[0].message.content.replace("```json", "").replace("```", "")
        return json.loads(content)
    except Exception as e:
        logger.error(f"AI Error: {e}")
        return {}

# --- ä¸šåŠ¡æ¥å£ ---

@router.post("/libraries")
def get_libs(config: AppConfig):
    url = f"{config.emby_host}/emby/Library/VirtualFolders"
    try:
        res = requests.get(url, params={'api_key': config.emby_api_key}, timeout=5)
        res.raise_for_status()
        return res.json()
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

def process_emby_items(items):
    result = []
    for item in items:
        # æ··åˆè¯»å– Tags å’Œ TagItems
        tags = item.get('Tags', [])
        if not tags and item.get('TagItems'):
            tags = [t.get('Name') for t in item.get('TagItems')]
        
        result.append({
            "id": item['Id'],
            "name": item.get('Name'),
            "year": item.get('ProductionYear'),
            "current_tags": tags,
            "overview": item.get('Overview', '')
        })
    return result

@router.post("/library_items")
def get_library_items(req: LibraryItemsRequest):
    url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items"
    params = {
        'IncludeItemTypes': 'Series,Movie',
        'Recursive': 'true',
        'ParentId': req.library_id,
        'Fields': 'Tags,TagItems,OriginalTitle,ProductionYear,Overview',
        'StartIndex': req.start_index,
        'SortBy': 'DateCreated',
        'SortOrder': 'Descending',
        'api_key': req.emby_api_key
    }
    if req.limit != -1: params['Limit'] = req.limit
    
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        return {"items": process_emby_items(res.json().get('Items', [])), "total": res.json().get('TotalRecordCount')}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.post("/search_items")
def search_items(req: SearchRequest):
    url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items"
    params = {
        'IncludeItemTypes': 'Series,Movie',
        'Recursive': 'true',
        'SearchTerm': req.search_term,
        'Fields': 'Tags,TagItems,OriginalTitle,ProductionYear,Overview',
        'api_key': req.emby_api_key
    }
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        return {"items": process_emby_items(res.json().get('Items', []))}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))



# 3. æ–°å¢ï¼šæ‰¹é‡åˆ†ææ¥å£ (æ”¾åˆ° ai_analyze_single é™„è¿‘)
@router.post("/ai_batch")
def ai_analyze_batch(req: AIBatchRequest, db: Session = Depends(get_db)):
    logger.info(f"ğŸ“¦ æ”¶åˆ°æ‰¹é‡ AI è¯·æ±‚ï¼ŒåŒ…å« {len(req.item_ids)} ä¸ªé¡¹ç›®")
    
    # --- ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡è·å– Emby ä¿¡æ¯ ---
    items_to_process = []
    id_map = {} # å»ºç«‹ Name -> ID çš„æ˜ å°„ï¼Œæ–¹ä¾¿å›å¡«
    
    for item_id in req.item_ids:
        # 1. å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ·æ–°ï¼Œå…ˆæŸ¥åº“
        if not req.force_refresh:
            cached = db.query(MediaTag).filter(MediaTag.item_id == item_id).first()
            if cached and cached.tags:
                logger.info(f"âš¡ï¸ [Batch] å‘½ä¸­ç¼“å­˜: {cached.name}")
                continue # å·²æœ‰ç¼“å­˜ï¼Œè·³è¿‡ AI

        # 2. å» Emby è·å–è¯¦æƒ…
        try:
            url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{item_id}"
            res = requests.get(url, params={'api_key': req.emby_api_key})
            if res.status_code == 200:
                item_data = res.json()
                # æ¸…æ´—åå­—
                raw_name = item_data.get('Name', '')
                clean_name = clean_string(raw_name)
                item_data['Name'] = clean_name # æ›¿æ¢ä¸ºå¹²å‡€åå­—
                
                items_to_process.append(item_data)
                id_map[clean_name] = item_id # è®°å½•æ˜ å°„å…³ç³»
        except Exception as e:
            logger.error(f"è·å– Emby é¡¹ç›® {item_id} å¤±è´¥: {e}")

    if not items_to_process:
        return {"status": "skipped", "message": "æ‰€æœ‰é¡¹ç›®å‡æœ‰ç¼“å­˜æˆ–è·å–å¤±è´¥"}

    # --- ç¬¬äºŒæ­¥ï¼šä¸€æ¬¡æ€§å‘ç»™ AI ---
    logger.info(f"ğŸ¤– [Batch] å‘é€ {len(items_to_process)} éƒ¨å‰§é›†ç»™ AI...")
    ai_results = ask_ai(items_to_process, req.sf_api_key)
    
    # --- ç¬¬ä¸‰æ­¥ï¼šè§£æå¹¶å…¥åº“ ---
    success_count = 0
    results_map = {} # è¿”å›ç»™å‰ç«¯æ›´æ–° UI ç”¨

    for item in items_to_process:
        name = item['Name']
        item_id = id_map.get(name)
        suggested = []

        # å°è¯•åŒ¹é… AI ç»“æœ
        if name in ai_results:
            suggested = ai_results[name]
        else:
            # æ¨¡ç³ŠåŒ¹é…
            for k in ai_results.keys():
                if clean_string(k) == name or name in k:
                    suggested = ai_results[k]
                    break
        
        if suggested:
            # å†™å…¥æ•°æ®åº“
            try:
                db_item = db.query(MediaTag).filter(MediaTag.item_id == item_id).first()
                if db_item:
                    db_item.tags = suggested
                    db_item.name = name
                else:
                    db.add(MediaTag(item_id=item_id, name=name, tags=suggested))
                
                results_map[item_id] = suggested
                success_count += 1
            except Exception as e:
                logger.error(f"æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ [Batch] AI æœªè¿”å› [{name}] çš„æ ‡ç­¾")

    try:
        db.commit()
    except:
        db.rollback()

    logger.info(f"âœ… [Batch] æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸå…¥åº“ {success_count} ä¸ª")
    
    # è¿”å›æˆåŠŸçš„ ID å’Œæ ‡ç­¾ï¼Œä¾›å‰ç«¯æ›´æ–°
    return {"status": "success", "results": results_map}



@router.post("/ai_single")
def ai_analyze_single(req: AISingleRequest, db: Session = Depends(get_db)):
    try:
        # 1. è¯»åº“
        if not req.force_refresh:
            cached = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
            if cached:
                return {"id": req.item_id, "name": cached.name, "suggested_tags": cached.tags, "source": "database"}

        # 2. è¯» Emby
        get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
        
        try:
            item_res = requests.get(get_url, params={'api_key': req.emby_api_key})
            item_res.raise_for_status()
            item = item_res.json()
        except Exception as e:
            logger.error(f"Emby è¯·æ±‚å¤±è´¥: {e}")
            raise HTTPException(status_code=400, detail=f"æ— æ³•è·å–å‰§é›†ä¿¡æ¯: {str(e)}")

        # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šæ¸…æ´— Emby è¿”å›çš„åå­— ğŸ”¥ğŸ”¥ğŸ”¥
        # Emby æœ‰æ—¶ä¼šè¿”å›å¸¦ \u200e çš„è„åå­—ï¼Œå¯¼è‡´ key åŒ¹é…å¤±è´¥
        raw_name = item.get('Name', '')
        name = clean_string(raw_name)
        
        # æ­¤æ—¶ item['Name'] è¿˜æ˜¯è„çš„ï¼Œä¸ºäº†è®© ask_ai å‘é€å¹²å‡€çš„åå­—ï¼Œæˆ‘ä»¬ä¸´æ—¶æ”¹ä¸€ä¸‹
        item['Name'] = name
        
        logger.info(f"ğŸ” å¤„ç†å‰§é›†: [{name}] (åŸå§‹åé•¿åº¦:{len(raw_name)} -> æ¸…æ´—å:{len(name)})")

        # 3. é—® AI
        ai_res = ask_ai([item], req.sf_api_key)
        
        # 4. åŒ¹é…ç»“æœ
        if name not in ai_res:
            logger.warning(f"âš ï¸ ç²¾ç¡®åŒ¹é…å¤±è´¥: æœŸæœ› [{name}]ï¼ŒAI è¿”å› {list(ai_res.keys())}")
            
            # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼šå¦‚æœ AI è¿”å›çš„ key åŒ…å«æˆ‘ä»¬çš„ nameï¼Œæˆ–è€…åè¿‡æ¥
            found_key = None
            for k in ai_res.keys():
                clean_k = clean_string(k)
                if clean_k == name or clean_k in name or name in clean_k:
                    found_key = k
                    break
            
            if found_key:
                logger.info(f"âœ… æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: [{found_key}]")
                suggested = ai_res[found_key]
            elif len(ai_res) == 1:
                # æœ€åçš„å…œåº•ï¼šåªè¿”å›äº†ä¸€ä¸ªç»“æœï¼Œé‚£å°±é»˜è®¤æ˜¯å®ƒ
                first_key = list(ai_res.keys())[0]
                logger.info(f"âœ… å…œåº•åŒ¹é…: ä½¿ç”¨å”¯ä¸€ç»“æœ [{first_key}]")
                suggested = ai_res[first_key]
            else:
                logger.error(f"âŒ å½»åº•åŒ¹é…å¤±è´¥ï¼Œæ— æ³•ç¡®å®š AI è¿”å›çš„æ˜¯å“ªéƒ¨å‰§ã€‚")
                raise HTTPException(status_code=500, detail=f"AI è¿”å›å‰§åä¸åŒ¹é…: {name}")
        else:
            suggested = ai_res[name]
        
        if not suggested: 
            raise HTTPException(status_code=500, detail="AI è¿”å›äº†ç©ºæ ‡ç­¾åˆ—è¡¨")

        # 5. å†™åº“
        try:
            db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
            if db_item:
                db_item.tags = suggested
                db_item.name = name
            else:
                db.add(MediaTag(item_id=req.item_id, name=name, tags=suggested))
            db.commit()
        except Exception as e:
            logger.error(f"æ•°æ®åº“ç¼“å­˜å¤±è´¥: {e}")

        return {"id": req.item_id, "name": name, "suggested_tags": suggested, "source": "ai"}
        
    except HTTPException as http_ex:
        raise http_ex
    except Exception as e:
        logger.error(f"ç³»ç»Ÿé”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))
    try:
        # 1. è¯»åº“
        if not req.force_refresh:
            cached = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
            if cached:
                return {"id": req.item_id, "name": cached.name, "suggested_tags": cached.tags, "source": "database"}

        # 2. è¯» Emby
        get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
        logger.info(f"æ­£åœ¨è·å– Emby æ•°æ®: {get_url}")
        
        try:
            item_res = requests.get(get_url, params={'api_key': req.emby_api_key})
            item_res.raise_for_status()
            item = item_res.json()
        except Exception as e:
            logger.error(f"Emby è¯·æ±‚å¤±è´¥: {e}")
            raise HTTPException(status_code=400, detail=f"æ— æ³•è·å–å‰§é›†ä¿¡æ¯: {str(e)}")

        # 3. é—® AI
        ai_res = ask_ai([item], req.sf_api_key)
        name = item.get('Name')
        
        # æ£€æŸ¥ AI è¿”å›ç»“æœæ˜¯å¦åŒ…å«è¯¥å‰§å
        if name not in ai_res:
            logger.error(f"âŒ AI è¿”å›çš„æ•°æ®ä¸­æ‰¾ä¸åˆ°å‰§å [{name}]ã€‚AI è¿”å› keys: {list(ai_res.keys())}")
            # å°è¯•æ¨¡ç³ŠåŒ¹é…æˆ–å–ç¬¬ä¸€ä¸ª
            if len(ai_res) == 1:
                first_key = list(ai_res.keys())[0]
                logger.warning(f"âš ï¸ å‰§åä¸åŒ¹é…ï¼Œå°è¯•ä½¿ç”¨ AI è¿”å›çš„å”¯ä¸€ç»“æœ: {first_key}")
                suggested = ai_res[first_key]
            else:
                raise HTTPException(status_code=500, detail=f"AI è¿”å›æ•°æ®å¼‚å¸¸ï¼Œæœªæ‰¾åˆ°å‰§å: {name}")
        else:
            suggested = ai_res[name]
        
        if not suggested: 
            raise HTTPException(status_code=500, detail="AI è¿”å›äº†ç©ºæ ‡ç­¾åˆ—è¡¨")

        # 4. å†™åº“
        try:
            db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
            if db_item:
                db_item.tags = suggested
                db_item.name = name
            else:
                db.add(MediaTag(item_id=req.item_id, name=name, tags=suggested))
            db.commit()
            logger.info("âœ… æ•°æ®åº“ç¼“å­˜å†™å…¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            # æ•°æ®åº“å¤±è´¥ä¸åº”è¯¥é˜»æ–­æµç¨‹ï¼Œåªæ‰“å°æ—¥å¿—å³å¯
            
        return {"id": req.item_id, "name": name, "suggested_tags": suggested, "source": "ai"}
        
    except HTTPException as http_ex:
        raise http_ex
    except Exception as e:
        # ğŸ”¥ æ•è·æ‰€æœ‰æœªçŸ¥çš„ Python é”™è¯¯ï¼ˆæ¯”å¦‚ç©ºæŒ‡é’ˆã€KeyErrorç­‰ï¼‰
        logger.error(f"ğŸ’¥ ç³»ç»Ÿä¸¥é‡é”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"åç«¯å†…éƒ¨é”™è¯¯: {str(e)}")
    # 1. è¯»åº“
    if not req.force_refresh:
        cached = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
        if cached:
            return {"id": req.item_id, "name": cached.name, "suggested_tags": cached.tags, "source": "database"}

    # 2. è¯» Emby
    get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
    try:
        item = requests.get(get_url, params={'api_key': req.emby_api_key}).json()
    except:
        raise HTTPException(status_code=400, detail="Emby Error")

    # 3. é—® AI
    ai_res = ask_ai([item], req.sf_api_key)
    name = item.get('Name')
    suggested = ai_res.get(name, [])
    
    if not suggested: raise HTTPException(status_code=500, detail="AI No Result")

    # 4. å†™åº“
    db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
    if db_item:
        db_item.tags = suggested
        db_item.name = name
    else:
        db.add(MediaTag(item_id=req.item_id, name=name, tags=suggested))
    db.commit()

    return {"id": req.item_id, "name": name, "suggested_tags": suggested, "source": "ai"}

# ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ”¯æŒè¦†ç›–æ›´æ–° (å®ç°åˆ é™¤/æ·»åŠ )
@router.post("/save_tags")
def save_tags(req: TagUpdateRequest, db: Session = Depends(get_db)):
    logger.info(f"ğŸ’¾ ä¿å­˜æ ‡ç­¾ ID: {req.item_id}, æ¨¡å¼: {'è¦†ç›–' if req.overwrite else 'åˆå¹¶'}")
    
    # 1. è·å–å…ƒæ•°æ®
    get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
    params = {'api_key': req.emby_api_key, 'Fields': 'Tags,TagItems,LockData,LockedFields'}
    try:
        item_data = requests.get(get_url, params=params).json()
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

    # 2. è§£é”
    if item_data.get('LockData'): item_data['LockData'] = False
    if item_data.get('LockedFields'): item_data['LockedFields'] = []

    # 3. æ ‡ç­¾å¤„ç†
    if req.overwrite:
        # è¦†ç›–æ¨¡å¼ï¼šå‰ç«¯ä¼ ä»€ä¹ˆï¼Œå°±å­˜ä»€ä¹ˆ (æ”¯æŒåˆ é™¤)
        final_tags = req.tags
    else:
        # åˆå¹¶æ¨¡å¼ (æ—§é€»è¾‘)
        existing = item_data.get('Tags', [])
        if not existing and item_data.get('TagItems'):
            existing = [t.get('Name') for t in item_data.get('TagItems')]
        final_tags = list(set(existing) | set(req.tags))

    item_data['Tags'] = final_tags
    
    # æ¸…ç†å¹²æ‰°å­—æ®µ
    if 'TagItems' in item_data: del item_data['TagItems']
    for k in ['MediaSources', 'PlayUserData', 'SeasonUserData', 'Container', 'Size']:
        if k in item_data: del item_data[k]

    # 4. å†™å…¥ Emby
    post_url = f"{req.emby_host}/emby/Items/{req.item_id}?api_key={req.emby_api_key}"
    try:
        res = requests.post(post_url, json=item_data, headers={'Content-Type': 'application/json'})
        if res.status_code not in [200, 204]:
             raise HTTPException(status_code=400, detail=res.text)
        
        # 5. åŒæ­¥æ›´æ–°æœ¬åœ°æ•°æ®åº“ (ä¿æŒç¼“å­˜ä¸€è‡´)
        db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
        if db_item:
            db_item.tags = final_tags
            db.commit()

        time.sleep(1) # ç¨å¾®å¿«ä¸€ç‚¹ï¼Œ1ç§’
        return {"status": "success", "tags": final_tags}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


