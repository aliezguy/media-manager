from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks, Request
from sqlalchemy.orm import Session
from database import get_db
from models import MediaTag
from pydantic import BaseModel
from typing import List, Optional
import requests
import json
import logging
import traceback
import asyncio
import re          # ğŸ‘ˆğŸ‘ˆğŸ‘ˆ å¿…é¡»è¡¥ä¸Šè¿™ä¸€è¡Œï¼
from openai import OpenAI
from config.settings import load_config
import time
from services.emby_service import get_item_info, update_item_tags

router = APIRouter()
logger = logging.getLogger("uvicorn")
# ... åœ¨è¿™é‡Œç²˜è´´ä½ åŸ main.py é‡Œ define çš„ Pydantic æ¨¡å‹ (LibraryItemsRequest ç­‰) ...
# --- Pydantic æ¨¡å‹ ---
class AppConfig(BaseModel):
    emby_host: str = ""
    emby_api_key: str = ""
    emby_user_id: str = ""
    sf_api_key: str = ""

class LibraryItemsRequest(AppConfig):
    library_id: str
    limit: int = 100
    start_index: int = 0

class SearchRequest(AppConfig):
    search_term: str

class AISingleRequest(AppConfig):
    item_id: str
    force_refresh: bool = False

class TagUpdateRequest(AppConfig):
    item_id: str
    tags: List[str] # æœ€ç»ˆè¦ä¿å­˜çš„æ ‡ç­¾åˆ—è¡¨
    overwrite: bool = True # é»˜è®¤ä¸ºè¦†ç›–æ¨¡å¼ï¼Œæ”¯æŒåˆ é™¤

# æ‰¹é‡è¯·æ±‚æ¨¡å‹
class AIBatchRequest(AppConfig):
    item_ids: List[str] # æ¥æ”¶ä¸€ç»„ ID
    force_refresh: bool = False

# ... åœ¨è¿™é‡Œç²˜è´´ process_emby_items, ask_ai ç­‰è¾…åŠ©å‡½æ•° ...
# ----------------------------------------------
# æ–°å¢ï¼šåç§°æ¸…æ´—å·¥å…·å‡½æ•°
# ----------------------------------------------
def clean_string(s):
    if not s: return ""
    # å»é™¤ \u200e (LRM), \u200f (RLM), \ufeff (BOM) ç­‰ä¸å¯è§å­—ç¬¦
    # åŒæ—¶ä¹Ÿå»é™¤é¦–å°¾ç©ºæ ¼
    return re.sub(r'[\u200b-\u200f\ufeff]', '', s).strip()    



async def process_emby_item_added(payload: dict):
    """åå°ä»»åŠ¡ï¼šå¤„ç† Emby å…¥åº“äº‹ä»¶ (ç›´æ¥ä½¿ç”¨ Webhook æ•°æ®ç‰ˆ)"""
    try:
        # 1. ğŸ”¥ã€æ–°å¢ã€‘æ‰“å°å®Œæ•´æŠ¥æ–‡ï¼Œæ–¹ä¾¿è°ƒè¯•æŸ¥çœ‹ Emby åˆ°åº•å‘äº†ä»€ä¹ˆ
        #logger.info(f"ğŸ“„ [è°ƒè¯•] æ”¶åˆ°å®Œæ•´ Webhook æŠ¥æ–‡: {json.dumps(payload, ensure_ascii=False)}")

        # 2. åŸºç¡€ä¿¡æ¯æå–
        item = payload.get("Item", {})
        if not item:
            logger.warning("âš ï¸ Payload ä¸­æ²¡æœ‰ 'Item' å­—æ®µï¼Œè·³è¿‡")
            return

        item_id = item.get("Id")
        name = item.get("Name", "")
        year = item.get("ProductionYear", "")
        item_type = item.get("Type")
        
        # æå– TMDB ID (å¦‚æœæœ‰çš„è¯ï¼Œæ—¥å¿—é‡Œæ‰“å°å‡ºæ¥ç¡®è®¤ä¸€ä¸‹)
        provider_ids = item.get("ProviderIds", {})
        tmdb_id = provider_ids.get("Tmdb")
        
        logger.info(f"   ğŸ“¦ [è§£æ] åª’ä½“: {name} ({year}) | ç±»å‹: {item_type} | TMDB: {tmdb_id}")

        # åªå¤„ç† Movie å’Œ Series
        if item_type not in ["Movie", "Series"]:
            return

        # 3. åŠ è½½é…ç½®
        config = load_config()
        sf_api_key = config.get("sf_api_key")
        if not sf_api_key:
            logger.warning(f"âš ï¸ æœªé…ç½® sf_api_keyï¼Œæ— æ³•è°ƒç”¨ AI")
            return

        # 4. ğŸ”¥ã€æ ¸å¿ƒä¿®æ”¹ã€‘ç›´æ¥æ„é€ æ•°æ®ä¼ ç»™ AIï¼Œä¸å†å›æŸ¥ Emby
        # æˆ‘ä»¬æ‰‹åŠ¨æ„é€ ä¸€ä¸ªå­—å…¸ï¼Œæ¨¡ä»¿ get_item_info è¿”å›çš„æ ¼å¼
        clean_name = clean_string(name)
        
        target_info = {
            "Name": clean_name,           # æ¸…æ´—åçš„åå­—
            "ProductionYear": year,       # å¹´ä»½
            "ProviderIds": provider_ids,  # ID ä¿¡æ¯
            "Overview": item.get("Overview", "") # ç®€ä»‹(å¦‚æœæœ‰)
        }
        
        logger.info(f"   ğŸ¤– æ­£åœ¨è¯·æ±‚ AI åˆ†æ: [{clean_name} {year}] ...")

        # 5. è°ƒç”¨ AI åˆ†æ
        ai_result = ask_ai([target_info], sf_api_key)
        
        if not ai_result:
            logger.warning("âš ï¸ AI æœªè¿”å›ä»»ä½•ç»“æœ")
            return

        # 6. è§£æç»“æœå¹¶åŒ¹é…
        suggested_tags = []
        
        # A. ç²¾ç¡®åŒ¹é…
        if clean_name in ai_result:
            suggested_tags = ai_result[clean_name]
            logger.info(f"   âœ… ç²¾ç¡®åŒ¹é…æˆåŠŸ")
        else:
            # B. æ¨¡ç³ŠåŒ¹é…
            match_found = False
            for k, v in ai_result.items():
                if clean_string(k) == clean_name or clean_name in k:
                    suggested_tags = v
                    match_found = True
                    logger.info(f"   âœ… æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: Key=[{k}]")
                    break
            
            # C. å…œåº• (AI åªè¿”å›äº†ä¸€ä¸ªç»“æœæ—¶)
            if not match_found and len(ai_result) == 1:
                suggested_tags = list(ai_result.values())[0]
                logger.info(f"   âš ï¸ ä½¿ç”¨å”¯ä¸€ç»“æœä½œä¸ºå…œåº•")

        # 7. æ‰§è¡Œæ›´æ–° (è¿™ä¸€æ­¥è¿˜æ˜¯éœ€è¦è°ƒ Emby æ¥å£ï¼Œä½†é€šå¸¸æ›´æ–°æ¥å£æ¯”æŸ¥è¯¢æ¥å£å®¹é”™ç‡é«˜)
        if suggested_tags:
            logger.info(f"   ğŸ· å‡†å¤‡æ‰“æ ‡ç­¾: {suggested_tags}")
            # è¿™é‡Œç¨å¾®å»¶è¿Ÿ 1 ç§’ï¼Œç»™ Emby æ•°æ®åº“ä¸€ç‚¹å–˜æ¯æ—¶é—´ï¼Œé˜²æ­¢é”æ­»
            await asyncio.sleep(1) 
            success = update_item_tags(item_id, suggested_tags)
            
            if success:
                logger.info(f"   ğŸ‰ [å®Œæˆ] æ ‡ç­¾æ›´æ–°æˆåŠŸï¼")
            else:
                logger.error(f"   âŒ æ ‡ç­¾æ›´æ–°å¤±è´¥ (å¯èƒ½æ˜¯ Emby è¿˜æ²¡å‡†å¤‡å¥½æ¥æ”¶å†™å…¥)")
        else:
            logger.warning(f"   âš ï¸ AI è¿”å›äº†ç»“æœï¼Œä½†æ— æ³•åŒ¹é…: {ai_result}")

    except Exception as e:
        logger.error(f"âŒ åå°ä»»åŠ¡å¤„ç†å¼‚å¸¸: {e}")
        logger.error(traceback.format_exc())

@router.post("/webhook/emby")
async def emby_webhook(request: Request, background_tasks: BackgroundTasks):
    logger.info("ğŸ“¨ æ”¶åˆ° Emby Webhook è¯·æ±‚")
    
    # 1. æ‰“å° Content-Type æ–¹ä¾¿è°ƒè¯•
    content_type = request.headers.get("content-type", "")
    logger.info(f"   - Content-Type: {content_type}")

    try:
        payload = {}
        
        # 2. æ ¹æ®ç±»å‹è§£ææ•°æ®
        if "application/json" in content_type:
            payload = await request.json()
            logger.info("   - å·²è§£æ JSON Body")
        elif "multipart/form-data" in content_type or "application/x-www-form-urlencoded" in content_type:
            # ğŸ”¥ è¿™é‡Œå°±æ˜¯ä¹‹å‰æŠ¥é”™çš„åœ°æ–¹ï¼Œå®‰è£… python-multipart åå°±å¥½äº†
            form = await request.form()
            data_str = form.get("data")
            if data_str:
                payload = json.loads(data_str)
                logger.info("   - å·²è§£æ Form Data ä¸­çš„ 'data' å­—æ®µ")
            else:
                logger.warning("   âš ï¸ Form Data ä¸­æœªæ‰¾åˆ° 'data' å­—æ®µï¼Œå°è¯•ç›´æ¥è§£æ")
                # æœ‰äº›ç‰ˆæœ¬çš„ Emby ç›´æ¥æŠŠ json æ”¾åœ¨ body é‡Œä½† header æ˜¯ form
                try:
                    body = await request.body()
                    payload = json.loads(body)
                except:
                    pass
        else:
            # å°è¯•æš´åŠ›è§£æ Body
            try:
                payload = await request.json()
                logger.info("   - å¼ºåˆ¶è§£æ JSON æˆåŠŸ")
            except:
                logger.warning(f"   âš ï¸ ä¸æ”¯æŒçš„ Content-Type ä¸”æ— æ³•è§£æ: {content_type}")
                return {"status": "unsupported_type"}

        # 3. æ£€æŸ¥äº‹ä»¶ç±»å‹
        event = payload.get("Event")
        logger.info(f"   - äº‹ä»¶ç±»å‹: {event}")
        
        # ç›‘å¬ "item.created" (æ–°å…¥åº“)
        # æ³¨æ„ï¼šEmby æµ‹è¯•é€šçŸ¥çš„ Event å¯èƒ½æ˜¯ "system.notification.test" æˆ–å…¶ä»–
        if event in ["item.created", "library.new"]:
            logger.info("   ğŸš€ è§¦å‘åå°å¤„ç†ä»»åŠ¡")
            background_tasks.add_task(process_emby_item_added, payload)
        elif event == "system.notification.test":
             logger.info("   ğŸ§ª æ”¶åˆ°æµ‹è¯•é€šçŸ¥ï¼Œè¿æ¥æ­£å¸¸ï¼")
        else:
            logger.info(f"   ğŸ’¤ å¿½ç•¥äº‹ä»¶: {event}")
            
        return {"status": "received"}
        
    except Exception as e:
        logger.error(f"âŒ Webhook æ¥æ”¶å¼‚å¸¸: {e}")
        logger.error(traceback.format_exc())
        return {"status": "error"}


# --- æ ¸å¿ƒé€»è¾‘ ---

def ask_ai(items, api_key):
    if not items or not api_key: return {}
    
    client = OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")
    simple_list = [{"name": i.get('Name'), "year": i.get('ProductionYear')} for i in items]
    
    logger.info(f"ğŸ¤– æ­£åœ¨è¯·æ±‚ AIï¼Œå‰§é›†ä¿¡æ¯: {simple_list}")

    prompt = f"""
    è¯·ä¸ºä»¥ä¸‹ç”µè§†å‰§æ‰“ä¸Š 8-10 ä¸ªç²¾å‡†çš„ä¸­æ–‡æ ‡ç­¾ã€‚
    æ ‡ç­¾èŒƒå›´åŒ…æ‹¬ä½†ä¸é™äºï¼šé¢˜æ(å¦‚å¤è£…,ç§‘å¹»)ã€é£æ ¼(å¦‚æ‚¬ç–‘,å–œå‰§)ã€å—ä¼—(å¦‚å¤§å¥³ä¸»,èŒåœº)ã€å…ƒç´ (å¦‚æƒè°‹,ç©¿è¶Š)ã€‚
    åªè¿”å›çº¯JSONæ ¼å¼ï¼Œä¸è¦Markdownæ ¼å¼ï¼Œä¸è¦ä»£ç å—ï¼š{{"å‰§å": ["æ ‡ç­¾1", "æ ‡ç­¾2"]}}
    
    å‰§é›†ï¼š{json.dumps(simple_list, ensure_ascii=False)}
    """
    try:
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2, stream=False
        )
        content = response.choices[0].message.content
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ è°ƒè¯•å…³é”®ï¼šæ‰“å° AI è¿”å›çš„åŸå§‹å­—ç¬¦ä¸² ğŸ”¥ğŸ”¥ğŸ”¥
        logger.info(f"ğŸ“¦ [DEBUG] AI åŸå§‹è¿”å›å†…å®¹: \n{content}")

        # æ¸…ç†å¯èƒ½çš„ markdown æ ‡è®°
        content = content.replace("```json", "").replace("```", "").strip()
        
        return json.loads(content)
    except Exception as e:
        # ğŸ”¥ğŸ”¥ğŸ”¥ è°ƒè¯•å…³é”®ï¼šæ‰“å°å®Œæ•´æŠ¥é”™å †æ ˆ ğŸ”¥ğŸ”¥ğŸ”¥
        logger.error(f"âŒ AI è§£æå¤±è´¥: {e}")
        logger.error(traceback.format_exc()) # æ‰“å°è¯¦ç»†æŠ¥é”™ä½ç½®
        return {}

# --- ä¸šåŠ¡æ¥å£ ---

@router.post("/libraries")
def get_libs(config: AppConfig):
    url = f"{config.emby_host}/emby/Library/VirtualFolders"
    try:
        res = requests.get(url, params={'api_key': config.emby_api_key}, timeout=5)
        res.raise_for_status()
        return res.json()
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

def process_emby_items(items):
    result = []
    for item in items:
        # æ··åˆè¯»å– Tags å’Œ TagItems
        tags = item.get('Tags', [])
        if not tags and item.get('TagItems'):
            tags = [t.get('Name') for t in item.get('TagItems')]
        
        result.append({
            "id": item['Id'],
            "name": item.get('Name'),
            "year": item.get('ProductionYear'),
            "current_tags": tags,
            "overview": item.get('Overview', '')
        })
    return result

@router.post("/library_items")
def get_library_items(req: LibraryItemsRequest):
    url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items"
    params = {
        'IncludeItemTypes': 'Series,Movie',
        'Recursive': 'true',
        'ParentId': req.library_id,
        'Fields': 'Tags,TagItems,OriginalTitle,ProductionYear,Overview',
        'StartIndex': req.start_index,
        'SortBy': 'DateCreated',
        'SortOrder': 'Descending',
        'api_key': req.emby_api_key
    }
    if req.limit != -1: params['Limit'] = req.limit
    
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        return {"items": process_emby_items(res.json().get('Items', [])), "total": res.json().get('TotalRecordCount')}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.post("/search_items")
def search_items(req: SearchRequest):
    url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items"
    params = {
        'IncludeItemTypes': 'Series,Movie',
        'Recursive': 'true',
        'SearchTerm': req.search_term,
        'Fields': 'Tags,TagItems,OriginalTitle,ProductionYear,Overview',
        'api_key': req.emby_api_key
    }
    try:
        res = requests.get(url, params=params)
        res.raise_for_status()
        return {"items": process_emby_items(res.json().get('Items', []))}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))



# 3. æ–°å¢ï¼šæ‰¹é‡åˆ†ææ¥å£ (æ”¾åˆ° ai_analyze_single é™„è¿‘)
@router.post("/ai_batch")
def ai_analyze_batch(req: AIBatchRequest, db: Session = Depends(get_db)):
    logger.info(f"ğŸ“¦ æ”¶åˆ°æ‰¹é‡ AI è¯·æ±‚ï¼ŒåŒ…å« {len(req.item_ids)} ä¸ªé¡¹ç›®")
    
    # --- ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡è·å– Emby ä¿¡æ¯ ---
    items_to_process = []
    id_map = {} # å»ºç«‹ Name -> ID çš„æ˜ å°„ï¼Œæ–¹ä¾¿å›å¡«
    
    for item_id in req.item_ids:
        # 1. å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ·æ–°ï¼Œå…ˆæŸ¥åº“
        if not req.force_refresh:
            cached = db.query(MediaTag).filter(MediaTag.item_id == item_id).first()
            if cached and cached.tags:
                logger.info(f"âš¡ï¸ [Batch] å‘½ä¸­ç¼“å­˜: {cached.name}")
                continue # å·²æœ‰ç¼“å­˜ï¼Œè·³è¿‡ AI

        # 2. å» Emby è·å–è¯¦æƒ…
        try:
            url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{item_id}"
            res = requests.get(url, params={'api_key': req.emby_api_key})
            if res.status_code == 200:
                item_data = res.json()
                # æ¸…æ´—åå­—
                raw_name = item_data.get('Name', '')
                clean_name = clean_string(raw_name)
                item_data['Name'] = clean_name # æ›¿æ¢ä¸ºå¹²å‡€åå­—
                
                items_to_process.append(item_data)
                id_map[clean_name] = item_id # è®°å½•æ˜ å°„å…³ç³»
        except Exception as e:
            logger.error(f"è·å– Emby é¡¹ç›® {item_id} å¤±è´¥: {e}")

    if not items_to_process:
        return {"status": "skipped", "message": "æ‰€æœ‰é¡¹ç›®å‡æœ‰ç¼“å­˜æˆ–è·å–å¤±è´¥"}

    # --- ç¬¬äºŒæ­¥ï¼šä¸€æ¬¡æ€§å‘ç»™ AI ---
    logger.info(f"ğŸ¤– [Batch] å‘é€ {len(items_to_process)} éƒ¨å‰§é›†ç»™ AI...")
    ai_results = ask_ai(items_to_process, req.sf_api_key)
    
    # --- ç¬¬ä¸‰æ­¥ï¼šè§£æå¹¶å…¥åº“ ---
    success_count = 0
    results_map = {} # è¿”å›ç»™å‰ç«¯æ›´æ–° UI ç”¨

    for item in items_to_process:
        name = item['Name']
        item_id = id_map.get(name)
        suggested = []

        # å°è¯•åŒ¹é… AI ç»“æœ
        if name in ai_results:
            suggested = ai_results[name]
        else:
            # æ¨¡ç³ŠåŒ¹é…
            for k in ai_results.keys():
                if clean_string(k) == name or name in k:
                    suggested = ai_results[k]
                    break
        
        if suggested:
            # å†™å…¥æ•°æ®åº“
            try:
                db_item = db.query(MediaTag).filter(MediaTag.item_id == item_id).first()
                if db_item:
                    db_item.tags = suggested
                    db_item.name = name
                else:
                    db.add(MediaTag(item_id=item_id, name=name, tags=suggested))
                
                results_map[item_id] = suggested
                success_count += 1
            except Exception as e:
                logger.error(f"æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ [Batch] AI æœªè¿”å› [{name}] çš„æ ‡ç­¾")

    try:
        db.commit()
    except:
        db.rollback()

    logger.info(f"âœ… [Batch] æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸå…¥åº“ {success_count} ä¸ª")
    
    # è¿”å›æˆåŠŸçš„ ID å’Œæ ‡ç­¾ï¼Œä¾›å‰ç«¯æ›´æ–°
    return {"status": "success", "results": results_map}



@router.post("/ai_single")
def ai_analyze_single(req: AISingleRequest, db: Session = Depends(get_db)):
    try:
        # 1. è¯»åº“
        if not req.force_refresh:
            cached = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
            if cached:
                return {"id": req.item_id, "name": cached.name, "suggested_tags": cached.tags, "source": "database"}

        # 2. è¯» Emby
        get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
        
        try:
            item_res = requests.get(get_url, params={'api_key': req.emby_api_key})
            item_res.raise_for_status()
            item = item_res.json()
        except Exception as e:
            logger.error(f"Emby è¯·æ±‚å¤±è´¥: {e}")
            raise HTTPException(status_code=400, detail=f"æ— æ³•è·å–å‰§é›†ä¿¡æ¯: {str(e)}")

        # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šæ¸…æ´— Emby è¿”å›çš„åå­— ğŸ”¥ğŸ”¥ğŸ”¥
        # Emby æœ‰æ—¶ä¼šè¿”å›å¸¦ \u200e çš„è„åå­—ï¼Œå¯¼è‡´ key åŒ¹é…å¤±è´¥
        raw_name = item.get('Name', '')
        name = clean_string(raw_name)
        
        # æ­¤æ—¶ item['Name'] è¿˜æ˜¯è„çš„ï¼Œä¸ºäº†è®© ask_ai å‘é€å¹²å‡€çš„åå­—ï¼Œæˆ‘ä»¬ä¸´æ—¶æ”¹ä¸€ä¸‹
        item['Name'] = name
        
        logger.info(f"ğŸ” å¤„ç†å‰§é›†: [{name}] (åŸå§‹åé•¿åº¦:{len(raw_name)} -> æ¸…æ´—å:{len(name)})")

        # 3. é—® AI
        ai_res = ask_ai([item], req.sf_api_key)
        
        # 4. åŒ¹é…ç»“æœ
        if name not in ai_res:
            logger.warning(f"âš ï¸ ç²¾ç¡®åŒ¹é…å¤±è´¥: æœŸæœ› [{name}]ï¼ŒAI è¿”å› {list(ai_res.keys())}")
            
            # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼šå¦‚æœ AI è¿”å›çš„ key åŒ…å«æˆ‘ä»¬çš„ nameï¼Œæˆ–è€…åè¿‡æ¥
            found_key = None
            for k in ai_res.keys():
                clean_k = clean_string(k)
                if clean_k == name or clean_k in name or name in clean_k:
                    found_key = k
                    break
            
            if found_key:
                logger.info(f"âœ… æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: [{found_key}]")
                suggested = ai_res[found_key]
            elif len(ai_res) == 1:
                # æœ€åçš„å…œåº•ï¼šåªè¿”å›äº†ä¸€ä¸ªç»“æœï¼Œé‚£å°±é»˜è®¤æ˜¯å®ƒ
                first_key = list(ai_res.keys())[0]
                logger.info(f"âœ… å…œåº•åŒ¹é…: ä½¿ç”¨å”¯ä¸€ç»“æœ [{first_key}]")
                suggested = ai_res[first_key]
            else:
                logger.error(f"âŒ å½»åº•åŒ¹é…å¤±è´¥ï¼Œæ— æ³•ç¡®å®š AI è¿”å›çš„æ˜¯å“ªéƒ¨å‰§ã€‚")
                raise HTTPException(status_code=500, detail=f"AI è¿”å›å‰§åä¸åŒ¹é…: {name}")
        else:
            suggested = ai_res[name]
        
        if not suggested: 
            raise HTTPException(status_code=500, detail="AI è¿”å›äº†ç©ºæ ‡ç­¾åˆ—è¡¨")

        # 5. å†™åº“
        try:
            db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
            if db_item:
                db_item.tags = suggested
                db_item.name = name
            else:
                db.add(MediaTag(item_id=req.item_id, name=name, tags=suggested))
            db.commit()
        except Exception as e:
            logger.error(f"æ•°æ®åº“ç¼“å­˜å¤±è´¥: {e}")

        return {"id": req.item_id, "name": name, "suggested_tags": suggested, "source": "ai"}
        
    except HTTPException as http_ex:
        raise http_ex
    except Exception as e:
        logger.error(f"ç³»ç»Ÿé”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

# ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ”¯æŒè¦†ç›–æ›´æ–° (å®ç°åˆ é™¤/æ·»åŠ )
@router.post("/save_tags")
def save_tags(req: TagUpdateRequest, db: Session = Depends(get_db)):
    logger.info(f"ğŸ’¾ ä¿å­˜æ ‡ç­¾ ID: {req.item_id}, æ¨¡å¼: {'è¦†ç›–' if req.overwrite else 'åˆå¹¶'}")
    
    # 1. è·å–å…ƒæ•°æ®
    get_url = f"{req.emby_host}/emby/Users/{req.emby_user_id}/Items/{req.item_id}"
    params = {'api_key': req.emby_api_key, 'Fields': 'Tags,TagItems,LockData,LockedFields'}
    try:
        item_data = requests.get(get_url, params=params).json()
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

    # 2. è§£é”
    if item_data.get('LockData'): item_data['LockData'] = False
    if item_data.get('LockedFields'): item_data['LockedFields'] = []

    # 3. æ ‡ç­¾å¤„ç†
    if req.overwrite:
        # è¦†ç›–æ¨¡å¼ï¼šå‰ç«¯ä¼ ä»€ä¹ˆï¼Œå°±å­˜ä»€ä¹ˆ (æ”¯æŒåˆ é™¤)
        final_tags = req.tags
    else:
        # åˆå¹¶æ¨¡å¼ (æ—§é€»è¾‘)
        existing = item_data.get('Tags', [])
        if not existing and item_data.get('TagItems'):
            existing = [t.get('Name') for t in item_data.get('TagItems')]
        final_tags = list(set(existing) | set(req.tags))

    item_data['Tags'] = final_tags
    
    # æ¸…ç†å¹²æ‰°å­—æ®µ
    if 'TagItems' in item_data: del item_data['TagItems']
    for k in ['MediaSources', 'PlayUserData', 'SeasonUserData', 'Container', 'Size']:
        if k in item_data: del item_data[k]

    # 4. å†™å…¥ Emby
    post_url = f"{req.emby_host}/emby/Items/{req.item_id}?api_key={req.emby_api_key}"
    try:
        res = requests.post(post_url, json=item_data, headers={'Content-Type': 'application/json'})
        if res.status_code not in [200, 204]:
             raise HTTPException(status_code=400, detail=res.text)
        
        # 5. åŒæ­¥æ›´æ–°æœ¬åœ°æ•°æ®åº“ (ä¿æŒç¼“å­˜ä¸€è‡´)
        db_item = db.query(MediaTag).filter(MediaTag.item_id == req.item_id).first()
        if db_item:
            db_item.tags = final_tags
            db.commit()

        time.sleep(1) # ç¨å¾®å¿«ä¸€ç‚¹ï¼Œ1ç§’
        return {"status": "success", "tags": final_tags}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


